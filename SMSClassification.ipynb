{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import nltk\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "from nltk.metrics import precision\n",
    "from nltk.metrics import recall\n",
    "from nltk.metrics import f_measure\n",
    "\n",
    "def vectorization(vectorizer,X_train,X_test):\n",
    "\tX_train_vec=vectorizer.fit_transform(X_train)\n",
    "\tX_test_vec=vectorizer.transform(X_test)\n",
    "\treturn X_train_vec,X_test_vec\n",
    "\n",
    "def trainModel_MNB(X_train_vec,y_train):\n",
    "\tnb_clf=MultinomialNB()\n",
    "\tnb_clf.fit(X_train_vec,y_train)\n",
    "\treturn nb_clf\n",
    "\n",
    "def trainModel_SVM(X_train_vec,y_train):\n",
    "\tsvm_clf=LinearSVC(C=1)\n",
    "\tsvm_clf.fit(X_train_vec,y_train)\n",
    "\treturn svm_clf\n",
    "\n",
    "train=pandas.read_csv(\"train.tsv\",delimiter='\\t')\n",
    "y=train[\"Label\"].values\n",
    "X=train[\"Text\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of NaiveBayes Model: 0.978333333333\n",
      "Confusion Matrix:\n",
      "[[514  11]\n",
      " [  2  73]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       1.00      0.98      0.99       525\n",
      "       spam       0.87      0.97      0.92        75\n",
      "\n",
      "avg / total       0.98      0.98      0.98       600\n",
      "\n",
      "\n",
      "Overall accuracy of Support Vector Machine Model: 0.983333333333\n",
      "Confusion Matrix:\n",
      "[[522   3]\n",
      " [  7  68]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.99      0.99      0.99       525\n",
      "       spam       0.96      0.91      0.93        75\n",
      "\n",
      "avg / total       0.98      0.98      0.98       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# default settings as baseline\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "unigram_count=CountVectorizer(encoding='latin-1',binary=False,min_df=5,stop_words=None)\n",
    "X_train_vec=unigram_count.fit_transform(X_train)\n",
    "X_test_vec=unigram_count.transform(X_test)\n",
    "nb_clf=MultinomialNB()\n",
    "nb_clf.fit(X_train_vec,y_train)\n",
    "svm_clf=LinearSVC(C=8)\n",
    "svm_clf.fit(X_train_vec,y_train)\n",
    "\n",
    "print \"Overall accuracy of NaiveBayes Model:\",nb_clf.score(X_test_vec,y_test)\n",
    "y_nb_pred=nb_clf.predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_nb_pred, labels=[\"ham\",\"spam\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "target_names = [\"ham\",\"spam\"]\n",
    "print(classification_report(y_test, y_nb_pred, target_names=target_names))\n",
    "\n",
    "\n",
    "print \"\\nOverall accuracy of Support Vector Machine Model:\",svm_clf.score(X_test_vec,y_test)\n",
    "y_svm_pred=svm_clf.predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_svm_pred, labels=[\"ham\",\"spam\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_svm_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of NaiveBayes Model: 0.985\n",
      "Confusion Matrix:\n",
      "[[518   7]\n",
      " [  2  73]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       1.00      0.99      0.99       525\n",
      "       spam       0.91      0.97      0.94        75\n",
      "\n",
      "avg / total       0.99      0.98      0.99       600\n",
      "\n",
      "9.9 \n",
      "Overall accuracy of Support Vector Machine Model: 0.983333333333\n",
      "Confusion Matrix:\n",
      "[[521   4]\n",
      " [  6  69]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.99      0.99      0.99       525\n",
      "       spam       0.95      0.92      0.93        75\n",
      "\n",
      "avg / total       0.98      0.98      0.98       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove stopword\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "unigram_count=CountVectorizer(encoding='latin-1',binary=False,min_df=5,stop_words='english')\n",
    "X_train_vec=unigram_count.fit_transform(X_train)\n",
    "X_test_vec=unigram_count.transform(X_test)\n",
    "nb_clf=MultinomialNB()\n",
    "nb_clf.fit(X_train_vec,y_train)\n",
    "\n",
    "print \"Overall accuracy of NaiveBayes Model:\",nb_clf.score(X_test_vec,y_test)\n",
    "y_nb_pred=nb_clf.predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_nb_pred, labels=[\"ham\",\"spam\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "target_names = [\"ham\",\"spam\"]\n",
    "print(classification_report(y_test, y_nb_pred, target_names=target_names))\n",
    "\n",
    "\n",
    "svm_clf=LinearSVC(C=8)\n",
    "svm_clf.fit(X_train_vec,y_train)\n",
    "print i/10.0,\"\\nOverall accuracy of Support Vector Machine Model:\",svm_clf.score(X_test_vec,y_test)\n",
    "y_svm_pred=svm_clf.predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_svm_pred, labels=[\"ham\",\"spam\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_svm_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall accuracy of Support Vector Machine Model: 0.985\n",
      "Confusion Matrix:\n",
      "[[522   3]\n",
      " [  6  69]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.99      0.99      0.99       525\n",
      "       spam       0.96      0.92      0.94        75\n",
      "\n",
      "avg / total       0.98      0.98      0.98       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# different C values\n",
    "svm_clf=LinearSVC(C=2)\n",
    "svm_clf.fit(X_train_vec,y_train)\n",
    "print \"\\nOverall accuracy of Support Vector Machine Model:\",svm_clf.score(X_test_vec,y_test)\n",
    "y_svm_pred=svm_clf.predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_svm_pred, labels=[\"ham\",\"spam\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_svm_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of NaiveBayes Model: 0.985\n",
      "Confusion Matrix:\n",
      "[[519   6]\n",
      " [  3  72]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.99      0.99      0.99       525\n",
      "       spam       0.92      0.96      0.94        75\n",
      "\n",
      "avg / total       0.99      0.98      0.99       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# N-grams\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "unigram_count=CountVectorizer(encoding='latin-1',ngram_range=(1,3),binary=False,min_df=5,stop_words='english')\n",
    "X_train_vec=unigram_count.fit_transform(X_train)\n",
    "X_test_vec=unigram_count.transform(X_test)\n",
    "nb_clf=MultinomialNB()\n",
    "nb_clf.fit(X_train_vec,y_train)\n",
    "\n",
    "\n",
    "print \"Overall accuracy of NaiveBayes Model:\",nb_clf.score(X_test_vec,y_test)\n",
    "y_nb_pred=nb_clf.predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_nb_pred, labels=[\"ham\",\"spam\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "target_names = [\"ham\",\"spam\"]\n",
    "print(classification_report(y_test, y_nb_pred, target_names=target_names))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall accuracy of Support Vector Machine Model: 0.986666666667\n",
      "Confusion Matrix:\n",
      "[[521   4]\n",
      " [  4  71]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.99      0.99      0.99       525\n",
      "       spam       0.95      0.95      0.95        75\n",
      "\n",
      "avg / total       0.99      0.99      0.99       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_clf=LinearSVC(C=3)\n",
    "svm_clf.fit(X_train_vec,y_train)\n",
    "print \"\\nOverall accuracy of Support Vector Machine Model:\",svm_clf.score(X_test_vec,y_test)\n",
    "y_svm_pred=svm_clf.predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_svm_pred, labels=[\"ham\",\"spam\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_svm_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of NaiveBayes Model: 0.981666666667\n",
      "Confusion Matrix:\n",
      "[[517   8]\n",
      " [  3  72]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.99      0.98      0.99       525\n",
      "       spam       0.90      0.96      0.93        75\n",
      "\n",
      "avg / total       0.98      0.98      0.98       600\n",
      "\n",
      "\n",
      "Overall accuracy of Support Vector Machine Model: 0.986666666667\n",
      "Confusion Matrix:\n",
      "[[523   2]\n",
      " [  6  69]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.99      1.00      0.99       525\n",
      "       spam       0.97      0.92      0.95        75\n",
      "\n",
      "avg / total       0.99      0.99      0.99       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# money as feature\n",
    "train=pandas.read_csv(\"money.tsv\",delimiter='\\t')\n",
    "y=train[\"Label\"].values\n",
    "X=train[\"Text\"].values\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "unigram_count=CountVectorizer(encoding='latin-1',binary=False,min_df=5,stop_words='english')\n",
    "X_train_vec=unigram_count.fit_transform(X_train)\n",
    "X_test_vec=unigram_count.transform(X_test)\n",
    "nb_clf=MultinomialNB()\n",
    "nb_clf.fit(X_train_vec,y_train)\n",
    "svm_clf=LinearSVC(C=1)\n",
    "svm_clf.fit(X_train_vec,y_train)\n",
    "\n",
    "print \"Overall accuracy of NaiveBayes Model:\",nb_clf.score(X_test_vec,y_test)\n",
    "y_nb_pred=nb_clf.predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_nb_pred, labels=[\"ham\",\"spam\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "target_names = [\"ham\",\"spam\"]\n",
    "print(classification_report(y_test, y_nb_pred, target_names=target_names))\n",
    "\n",
    "\n",
    "print \"\\nOverall accuracy of Support Vector Machine Model:\",svm_clf.score(X_test_vec,y_test)\n",
    "y_svm_pred=svm_clf.predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_svm_pred, labels=[\"ham\",\"spam\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_svm_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of NaiveBayes Model: 0.981666666667\n",
      "Confusion Matrix:\n",
      "[[517   8]\n",
      " [  3  72]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.99      0.98      0.99       525\n",
      "       spam       0.90      0.96      0.93        75\n",
      "\n",
      "avg / total       0.98      0.98      0.98       600\n",
      "\n",
      "\n",
      "Overall accuracy of Support Vector Machine Model: 0.983333333333\n",
      "Confusion Matrix:\n",
      "[[521   4]\n",
      " [  6  69]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.99      0.99      0.99       525\n",
      "       spam       0.95      0.92      0.93        75\n",
      "\n",
      "avg / total       0.98      0.98      0.98       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# url as feature\n",
    "train=pandas.read_csv(\"url.tsv\",delimiter='\\t')\n",
    "y=train[\"Label\"].values\n",
    "X=train[\"Text\"].values\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "unigram_count=CountVectorizer(encoding='latin-1',binary=False,min_df=5,stop_words='english')\n",
    "X_train_vec=unigram_count.fit_transform(X_train)\n",
    "X_test_vec=unigram_count.transform(X_test)\n",
    "nb_clf=MultinomialNB()\n",
    "nb_clf.fit(X_train_vec,y_train)\n",
    "svm_clf=LinearSVC(C=1)\n",
    "svm_clf.fit(X_train_vec,y_train)\n",
    "\n",
    "print \"Overall accuracy of NaiveBayes Model:\",nb_clf.score(X_test_vec,y_test)\n",
    "y_nb_pred=nb_clf.predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_nb_pred, labels=[\"ham\",\"spam\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "target_names = [\"ham\",\"spam\"]\n",
    "print(classification_report(y_test, y_nb_pred, target_names=target_names))\n",
    "\n",
    "\n",
    "print \"\\nOverall accuracy of Support Vector Machine Model:\",svm_clf.score(X_test_vec,y_test)\n",
    "y_svm_pred=svm_clf.predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_svm_pred, labels=[\"ham\",\"spam\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_svm_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of NaiveBayes Model: 0.981666666667\n",
      "Confusion Matrix:\n",
      "[[517   8]\n",
      " [  3  72]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.99      0.98      0.99       525\n",
      "       spam       0.90      0.96      0.93        75\n",
      "\n",
      "avg / total       0.98      0.98      0.98       600\n",
      "\n",
      "\n",
      "Overall accuracy of Support Vector Machine Model: 0.985\n",
      "Confusion Matrix:\n",
      "[[522   3]\n",
      " [  6  69]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.99      0.99      0.99       525\n",
      "       spam       0.96      0.92      0.94        75\n",
      "\n",
      "avg / total       0.98      0.98      0.98       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# email as feature\n",
    "train=pandas.read_csv(\"email.tsv\",delimiter='\\t')\n",
    "y=train[\"Label\"].values\n",
    "X=train[\"Text\"].values\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "unigram_count=CountVectorizer(encoding='latin-1',binary=False,min_df=5,stop_words='english')\n",
    "X_train_vec=unigram_count.fit_transform(X_train)\n",
    "X_test_vec=unigram_count.transform(X_test)\n",
    "nb_clf=MultinomialNB()\n",
    "nb_clf.fit(X_train_vec,y_train)\n",
    "svm_clf=LinearSVC(C=1)\n",
    "svm_clf.fit(X_train_vec,y_train)\n",
    "\n",
    "print \"Overall accuracy of NaiveBayes Model:\",nb_clf.score(X_test_vec,y_test)\n",
    "y_nb_pred=nb_clf.predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_nb_pred, labels=[\"ham\",\"spam\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "target_names = [\"ham\",\"spam\"]\n",
    "print(classification_report(y_test, y_nb_pred, target_names=target_names))\n",
    "\n",
    "\n",
    "print \"\\nOverall accuracy of Support Vector Machine Model:\",svm_clf.score(X_test_vec,y_test)\n",
    "y_svm_pred=svm_clf.predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_svm_pred, labels=[\"ham\",\"spam\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_svm_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of NaiveBayes Model: 0.985\n",
      "Confusion Matrix:\n",
      "[[518   7]\n",
      " [  2  73]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       1.00      0.99      0.99       525\n",
      "       spam       0.91      0.97      0.94        75\n",
      "\n",
      "avg / total       0.99      0.98      0.99       600\n",
      "\n",
      "\n",
      "Overall accuracy of Support Vector Machine Model: 0.99\n",
      "Confusion Matrix:\n",
      "[[523   2]\n",
      " [  4  71]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.99      1.00      0.99       525\n",
      "       spam       0.97      0.95      0.96        75\n",
      "\n",
      "avg / total       0.99      0.99      0.99       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# phone number as feature\n",
    "train=pandas.read_csv(\"phone.tsv\",delimiter='\\t')\n",
    "y=train[\"Label\"].values\n",
    "X=train[\"Text\"].values\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "unigram_count=CountVectorizer(encoding='latin-1',binary=False,min_df=5,stop_words='english')\n",
    "X_train_vec=unigram_count.fit_transform(X_train)\n",
    "X_test_vec=unigram_count.transform(X_test)\n",
    "nb_clf=MultinomialNB()\n",
    "nb_clf.fit(X_train_vec,y_train)\n",
    "svm_clf=LinearSVC(C=0.4)\n",
    "svm_clf.fit(X_train_vec,y_train)\n",
    "\n",
    "print \"Overall accuracy of NaiveBayes Model:\",nb_clf.score(X_test_vec,y_test)\n",
    "y_nb_pred=nb_clf.predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_nb_pred, labels=[\"ham\",\"spam\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "target_names = [\"ham\",\"spam\"]\n",
    "print(classification_report(y_test, y_nb_pred, target_names=target_names))\n",
    "\n",
    "\n",
    "print \"\\nOverall accuracy of Support Vector Machine Model:\",svm_clf.score(X_test_vec,y_test)\n",
    "y_svm_pred=svm_clf.predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_svm_pred, labels=[\"ham\",\"spam\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_svm_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of NaiveBayes Model: 0.985\n",
      "Confusion Matrix:\n",
      "[[518   7]\n",
      " [  2  73]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       1.00      0.99      0.99       525\n",
      "       spam       0.91      0.97      0.94        75\n",
      "\n",
      "avg / total       0.99      0.98      0.99       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# money and phone number as feature\n",
    "train=pandas.read_csv(\"money+phone.tsv\",delimiter='\\t')\n",
    "y=train[\"Label\"].values\n",
    "X=train[\"Text\"].values\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "unigram_count=CountVectorizer(encoding='latin-1',binary=False,min_df=5,stop_words='english')\n",
    "X_train_vec=unigram_count.fit_transform(X_train)\n",
    "X_test_vec=unigram_count.transform(X_test)\n",
    "nb_clf=MultinomialNB()\n",
    "nb_clf.fit(X_train_vec,y_train)\n",
    "\n",
    "print \"Overall accuracy of NaiveBayes Model:\",nb_clf.score(X_test_vec,y_test)\n",
    "y_nb_pred=nb_clf.predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_nb_pred, labels=[\"ham\",\"spam\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "target_names = [\"ham\",\"spam\"]\n",
    "print(classification_report(y_test, y_nb_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.9 \n",
      "Overall accuracy of Support Vector Machine Model: 0.99\n",
      "Confusion Matrix:\n",
      "[[523   2]\n",
      " [  4  71]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.99      1.00      0.99       525\n",
      "       spam       0.97      0.95      0.96        75\n",
      "\n",
      "avg / total       0.99      0.99      0.99       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_clf=LinearSVC(C=10,class_weight={\"spam\":0.13,\"ham\":0.87})\n",
    "svm_clf.fit(X_train_vec,y_train)\n",
    "print i/10.0,\"\\nOverall accuracy of Support Vector Machine Model:\",svm_clf.score(X_test_vec,y_test)\n",
    "y_svm_pred=svm_clf.predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_svm_pred, labels=[\"ham\",\"spam\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_svm_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy of NaiveBayes Model: 0.985\n",
      "Confusion Matrix:\n",
      "[[518   7]\n",
      " [  2  73]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       1.00      0.99      0.99       525\n",
      "       spam       0.91      0.97      0.94        75\n",
      "\n",
      "avg / total       0.99      0.98      0.99       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# money, phone number and email as feature\n",
    "train=pandas.read_csv(\"money+phone+email.tsv\",delimiter='\\t')\n",
    "y=train[\"Label\"].values\n",
    "X=train[\"Text\"].values\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "unigram_count=CountVectorizer(encoding='latin-1',binary=False,min_df=5,stop_words='english')\n",
    "X_train_vec=unigram_count.fit_transform(X_train)\n",
    "X_test_vec=unigram_count.transform(X_test)\n",
    "nb_clf=MultinomialNB()\n",
    "nb_clf.fit(X_train_vec,y_train)\n",
    "\n",
    "print \"Overall accuracy of NaiveBayes Model:\",nb_clf.score(X_test_vec,y_test)\n",
    "y_nb_pred=nb_clf.predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_nb_pred, labels=[\"ham\",\"spam\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "target_names = [\"ham\",\"spam\"]\n",
    "print(classification_report(y_test, y_nb_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall accuracy of Support Vector Machine Model: 0.991666666667\n",
      "Confusion Matrix:\n",
      "[[523   2]\n",
      " [  3  72]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.99      1.00      1.00       525\n",
      "       spam       0.97      0.96      0.97        75\n",
      "\n",
      "avg / total       0.99      0.99      0.99       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_clf=LinearSVC(C=0.4)\n",
    "svm_clf.fit(X_train_vec,y_train)\n",
    "print \"\\nOverall accuracy of Support Vector Machine Model:\",svm_clf.score(X_test_vec,y_test)\n",
    "y_svm_pred=svm_clf.predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_svm_pred, labels=[\"ham\",\"spam\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_svm_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model with highest accuracy\n",
    "train=pandas.read_csv(\"tr.tsv\",delimiter='\\t')\n",
    "y=train[\"Label\"].values\n",
    "X=train[\"Text\"].values\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "unigram_count=CountVectorizer(encoding='latin-1',binary=False,min_df=5,stop_words='english')\n",
    "X_train_vec=unigram_count.fit_transform(X_train)\n",
    "X_test_vec=unigram_count.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall accuracy of Support Vector Machine Model: 0.993333333333\n",
      "Confusion Matrix:\n",
      "[[523   2]\n",
      " [  2  73]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       1.00      1.00      1.00       525\n",
      "       spam       0.97      0.97      0.97        75\n",
      "\n",
      "avg / total       0.99      0.99      0.99       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_clf=LinearSVC(C=1)\n",
    "svm_clf.fit(X_train_vec,y_train)\n",
    "\n",
    "\n",
    "print \"\\nOverall accuracy of Support Vector Machine Model:\",svm_clf.score(X_test_vec,y_test)\n",
    "y_svm_pred=svm_clf.predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_svm_pred, labels=[\"ham\",\"spam\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_svm_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall accuracy of Support Vector Machine Model: 0.99\n",
      "Confusion Matrix:\n",
      "[[525   0]\n",
      " [  6  69]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.99      1.00      0.99       525\n",
      "       spam       1.00      0.92      0.96        75\n",
      "\n",
      "avg / total       0.99      0.99      0.99       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model with best ham recall\n",
    "svm_clf=LinearSVC(C=1,class_weight={\"spam\":0.13,\"ham\":0.87})\n",
    "svm_clf.fit(X_train_vec,y_train)\n",
    "\n",
    "print \"\\nOverall accuracy of Support Vector Machine Model:\",svm_clf.score(X_test_vec,y_test)\n",
    "y_svm_pred=svm_clf.predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_svm_pred, labels=[\"ham\",\"spam\"])\n",
    "print \"Confusion Matrix:\"\n",
    "print cm\n",
    "print classification_report(y_test, y_svm_pred, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your credits have been topped up for urlurlurl Your renewal Pin is tgxxrz spam\n",
      "You are now unsubscribed all services. Get tons of sexy babes or hunks straight to your phone! go to urlurlurl No subscriptions. spam\n",
      "Hi ya babe x you 4goten bout me?' scammers getting smart..Though this is a regular vodafone no, if you respond you get further prem rate msg/subscription. Other nos used also. Beware! spam\n",
      "accordingly. I repeat, just text the word ok on your mobile phone and send spam\n",
      "85233 FREE>Ringtone!Reply REAL spam\n",
      "FreeMsg>FAV XMAS TONES!Reply REAL spam\n"
     ]
    }
   ],
   "source": [
    "# trouble shooting, find out the falsely classified messages\n",
    "for i in range(len(svm_clf.predict(X_test_vec))):\n",
    "    if svm_clf.predict(X_test_vec)[i]!=y_test[i]:\n",
    "        print X_test[i],y_test[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use nltk to build the model\n",
    "documents=[]\n",
    "for i in range(len(y)):\n",
    "    documents.append((X[i].split(),y[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bag_of_words(words):\n",
    "\treturn dict([(word,True) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets=[(bag_of_words(document),tag) for (document,tag) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size=int(len(featuresets)*0.8)\n",
    "train_set,test_set=featuresets[:size],featuresets[size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use nltk to build a mnb model\n",
    "classifier=nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use nltk to build a svm model\n",
    "svm_classifier=nltk.classify.SklearnClassifier(LinearSVC()).train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure(classifier,test_set):\n",
    "    groundTruth=[]\n",
    "    predictionResult=[]\n",
    "\n",
    "    for (features,label) in test_set:\n",
    "        groundTruth.append(label)\n",
    "        predictionResult.append(classifier.classify(features))\n",
    "    \n",
    "    cm=ConfusionMatrix(groundTruth,predictionResult)\n",
    "    print \"Confusion Matrix:\"\n",
    "    print cm\n",
    "\n",
    "    groundTruth_pos=set([i for i,label in enumerate(groundTruth) if label=='ham'])\n",
    "    groundTruth_neg=set([i for i,label in enumerate(groundTruth) if label=='spam'])\n",
    "    predictionResult_pos=set([i for i,label in enumerate(predictionResult) if label=='ham'])\n",
    "    predictionResult_neg=set([i for i,label in enumerate(predictionResult) if label=='spam'])    \n",
    "\n",
    "    print \"Overall Accuracy:\",nltk.classify.accuracy(classifier,test_set)\n",
    "    print \"Result of Positive：\"\n",
    "    printmeasures(\"ham\",groundTruth_pos,predictionResult_pos)\n",
    "    print \"Result of Negative：\"\n",
    "    printmeasures(\"spam\",groundTruth_neg,predictionResult_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printmeasures(label, groundTruth_set, predictionResult_set):\n",
    "    print label,'precision:',precision(groundTruth_set,predictionResult_set)\n",
    "    print label,'recall:',recall(groundTruth_set,predictionResult_set)\n",
    "    print label,'F-measure:',f_measure(groundTruth_set,predictionResult_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "     |       s |\n",
      "     |   h   p |\n",
      "     |   a   a |\n",
      "     |   m   m |\n",
      "-----+---------+\n",
      " ham |<453> 71 |\n",
      "spam |   . <76>|\n",
      "-----+---------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Overall Accuracy: 0.881666666667\n",
      "Result of Positive：\n",
      "ham precision: 1.0\n",
      "ham recall: 0.864503816794\n",
      "ham F-measure: 0.927328556807\n",
      "Result of Negative：\n",
      "spam precision: 0.517006802721\n",
      "spam recall: 1.0\n",
      "spam F-measure: 0.681614349776\n"
     ]
    }
   ],
   "source": [
    "# evaluation of mnb model\n",
    "measure(classifier,test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "     |       s |\n",
      "     |   h   p |\n",
      "     |   a   a |\n",
      "     |   m   m |\n",
      "-----+---------+\n",
      " ham |<524>  . |\n",
      "spam |  11 <65>|\n",
      "-----+---------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "Overall Accuracy: 0.981666666667\n",
      "Result of Positive：\n",
      "ham precision: 0.979439252336\n",
      "ham recall: 1.0\n",
      "ham F-measure: 0.989612842304\n",
      "Result of Negative：\n",
      "spam precision: 1.0\n",
      "spam recall: 0.855263157895\n",
      "spam F-measure: 0.921985815603\n"
     ]
    }
   ],
   "source": [
    "# evaluation of svm model\n",
    "measure(svm_classifier,test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
